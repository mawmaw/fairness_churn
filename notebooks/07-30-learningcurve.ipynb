{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# !pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "# from yellowbrick.model_selection import learning_curve\n",
    "\n",
    "\n",
    "# SMOTE and Near Miss\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "# !pip install 'aif360[AdversarialDebiasing]'\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.explainers import MetricTextExplainer, MetricJSONExplainer\n",
    "# from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import warnings\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process start \t2022-03-09 16:43:57.840059\n"
     ]
    }
   ],
   "source": [
    "def logTime(msg):\n",
    "    print('{} \\t{}'.format(msg, datetime.datetime.now()))\n",
    "logTime('Process start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical: Index(['age', 'gender', 'hsbb_area', 'speed', 'price_start', 'complain_count',\n",
      "       'churn', 'median_outstanding', 'technical_problem_count', 'is_senior',\n",
      "       'avg_download', 'avg_upload', 'avg_voice_usage'],\n",
      "      dtype='object')\n",
      "\n",
      "Categorical: Index(['contract_period', 'race', 't_location'], dtype='object')\n",
      "46\n",
      "Wall time: 186 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['age', 'gender', 'hsbb_area', 'speed', 'price_start', 'complain_count',\n",
       "       'churn', 'median_outstanding', 'technical_problem_count', 'is_senior',\n",
       "       'avg_download', 'avg_upload', 'avg_voice_usage', 'race_B', 'race_C',\n",
       "       'race_I', 'race_M', 'race_O', 't_location_Zone-AJP',\n",
       "       't_location_Zone-AKM', 't_location_Zone-BAL', 't_location_Zone-BKK',\n",
       "       't_location_Zone-BLS', 't_location_Zone-CSM', 't_location_Zone-GCK',\n",
       "       't_location_Zone-GHP', 't_location_Zone-GPP', 't_location_Zone-GRT',\n",
       "       't_location_Zone-IRM', 't_location_Zone-KDS', 't_location_Zone-KRP',\n",
       "       't_location_Zone-NSN', 't_location_Zone-PBP', 't_location_Zone-PDK',\n",
       "       't_location_Zone-RLK', 't_location_Zone-SRJ', 't_location_Zone-TLK',\n",
       "       't_location_Zone-TLS', 't_location_Zone-UBS', 't_location_Zone-URJ',\n",
       "       't_location_Zone-UWT', 'contract_period_1', 'contract_period_12',\n",
       "       'contract_period_18', 'contract_period_24', 'contract_period_36'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.read_csv(\"\"\"..\\data\\interim\\data_100000-30percent.csv\"\"\")\n",
    "# data = pd.read_csv(\"\"\"../data/interim/data_100000-5percent.csv\"\"\")\n",
    "data2 = data.drop(['customer'], axis=1)\n",
    "# data2 = data2.drop(['tenure'], axis=1)\n",
    "# data2 = data2.drop(['comeback_product'], axis=1)\n",
    "\n",
    "data2['gender'] = data2['gender'].astype(int)\n",
    "# data2['churn'] = data2['churn'].astype(object)\n",
    "data2['is_senior'] = data2['is_senior'].astype(int)\n",
    "data2['contract_period'] = data2['contract_period'].astype(object)\n",
    "\n",
    "numerical = data2.select_dtypes(['number']).columns\n",
    "print(f'Numerical: {numerical}\\n')\n",
    "\n",
    "categorical = data2.columns.difference(numerical)\n",
    "\n",
    "data2[categorical] = data2[categorical].astype('object')\n",
    "print(f'Categorical: {categorical}')\n",
    "\n",
    "data2 = pd.get_dummies(data2)\n",
    "\n",
    "X_original = data2.drop('churn', axis=1)\n",
    "y_original = data2['churn']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 42)\n",
    "print(len(data2.keys()))\n",
    "data2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append((\"LightGBM\", LGBMClassifier()))\n",
    "models.append(('Gradient Boosting', GradientBoostingClassifier()))\n",
    "models.append(('Logistic Reg.', LogisticRegression(max_iter=1000)))\n",
    "\n",
    "models.append(('XGBClassifier', XGBClassifier(use_label_encoder=False)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "\n",
    "methods = ['original', 'adasyn', 'smote', 'rus', 'ros']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIF360 Dataset Preparation\n",
    "\n",
    "all_labels = ['age', 'gender', 'hsbb_area', 'speed', 'price_start', 'complain_count',\n",
    "       'churn', 'median_outstanding', 'technical_problem_count', 'is_senior',\n",
    "       'avg_download', 'avg_upload', 'avg_voice_usage', 'race_B', 'race_C',\n",
    "       'race_I', 'race_M', 'race_O', 't_location_Zone-AJP',\n",
    "       't_location_Zone-AKM', 't_location_Zone-BAL', 't_location_Zone-BKK',\n",
    "       't_location_Zone-BLS', 't_location_Zone-CSM', 't_location_Zone-GCK',\n",
    "       't_location_Zone-GHP', 't_location_Zone-GPP', 't_location_Zone-GRT',\n",
    "       't_location_Zone-IRM', 't_location_Zone-KDS', 't_location_Zone-KRP',\n",
    "       't_location_Zone-NSN', 't_location_Zone-PBP', 't_location_Zone-PDK',\n",
    "       't_location_Zone-RLK', 't_location_Zone-SRJ', 't_location_Zone-TLK',\n",
    "       't_location_Zone-TLS', 't_location_Zone-UBS', 't_location_Zone-URJ',\n",
    "       't_location_Zone-UWT', \n",
    "        # 'contract_period_1', \n",
    "        'contract_period_12',\n",
    "       'contract_period_18', 'contract_period_24', 'contract_period_36']\n",
    "\n",
    "features = ['age', 'gender', 'hsbb_area', 'speed', 'price_start', 'complain_count',\n",
    "       'churn', 'median_outstanding', 'technical_problem_count', 'is_senior',\n",
    "       'avg_download', 'avg_upload', 'avg_voice_usage', 'race_B', 'race_C',\n",
    "       'race_I', 'race_M', 'race_O', 't_location_Zone-AJP',\n",
    "       't_location_Zone-AKM', 't_location_Zone-BAL', 't_location_Zone-BKK',\n",
    "       't_location_Zone-BLS', 't_location_Zone-CSM', 't_location_Zone-GCK',\n",
    "       't_location_Zone-GHP', 't_location_Zone-GPP', 't_location_Zone-GRT',\n",
    "       't_location_Zone-IRM', 't_location_Zone-KDS', 't_location_Zone-KRP',\n",
    "       't_location_Zone-NSN', 't_location_Zone-PBP', 't_location_Zone-PDK',\n",
    "       't_location_Zone-RLK', 't_location_Zone-SRJ', 't_location_Zone-TLK',\n",
    "       't_location_Zone-TLS', 't_location_Zone-UBS', 't_location_Zone-URJ',\n",
    "       't_location_Zone-UWT', \n",
    "        # 'contract_period_1', \n",
    "        'contract_period_12',\n",
    "       'contract_period_18', 'contract_period_24', 'contract_period_36']\n",
    "\n",
    "\n",
    "class TMDataset(StandardDataset):\n",
    "    def __init__(self, \n",
    "             label_name='churn',\n",
    "             favorable_classes=[1.0],\n",
    "                 \n",
    "             protected_attribute_names=[\n",
    "                'gender', \n",
    "#                 'is_senior',\n",
    "#                 'race_O',\n",
    "             ],\n",
    "    \n",
    "             privileged_classes=[\n",
    "                [1.0,], \n",
    "#                 [0.0,],\n",
    "#                 [0.0,],\n",
    "             ],\n",
    "                 \n",
    "             instance_weights_name=None,\n",
    "             categorical_features=[],\n",
    "             features_to_keep=features, \n",
    "             features_to_drop=[],\n",
    "             custom_preprocessing=None,\n",
    "             metadata=None,\n",
    "             csv_file_name='',\n",
    "             data_frame=None,\n",
    "    ):\n",
    "        \n",
    "        if data_frame is not None:\n",
    "            aif_df = data_frame\n",
    "        else:\n",
    "            aif_df = pd.read_csv(csv_file_name)\n",
    "        \n",
    "        #df.reset_index(drop=True, inplace=True)\n",
    "        # Preprocessing\n",
    "        \n",
    "        super().__init__(\n",
    "            df=aif_df, label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=instance_weights_name,\n",
    "            categorical_features=categorical_features,\n",
    "            features_to_keep=features_to_keep,\n",
    "            features_to_drop=features_to_drop,\n",
    "            custom_preprocessing=custom_preprocessing, \n",
    "            metadata=metadata,\n",
    "     \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sampling(method_name, X, y):\n",
    "    if method_name == 'original':\n",
    "        return (X, y)\n",
    "    elif method_name == 'adasyn':\n",
    "        adasyn = ADASYN(sampling_strategy='minority', random_state=420, n_neighbors=5)\n",
    "        return adasyn.fit_resample(X, y)\n",
    "    elif method_name == 'smote':\n",
    "        os = SMOTE(random_state=41)\n",
    "        return os.fit_resample(X, y)\n",
    "    elif method_name == 'ros':\n",
    "        random_over_sampler = RandomOverSampler(random_state=42)\n",
    "        return random_over_sampler.fit_resample(X, y)\n",
    "    elif method_name == 'rus':\n",
    "        random_under_sampler = RandomUnderSampler(random_state=42)\n",
    "        return random_under_sampler.fit_resample(X, y)\n",
    "    else:\n",
    "        print('UNKNOWN METHOD !!') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learningcurve(classfier, X, y):\n",
    "    # classfier = model\n",
    "    # print('Process started at {}'.format(datetime.datetime.now())) \n",
    "    train_sizes_initial = np.linspace(0.01, 1.0, 50)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        classfier, X, y, cv=10, scoring='accuracy', \n",
    "        n_jobs=-1, train_sizes=train_sizes_initial)\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.subplots(1, figsize=(10,10))\n",
    "    plt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n",
    "\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.pause(0.05)\n",
    "    # print('Process end at {}'.format(datetime.datetime.now())) \n",
    "    # print(learning_curve(model, X, y, cv=30, scoring='accuracy'))\n",
    "\n",
    "    # end plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModels(model_index, method_index):\n",
    "    name, model = models[model_index - 1]\n",
    "    method = methods[method_index - 1]\n",
    "    display(HTML(f'<h2>{model_index}.{method_index} {name} - {method} </h2>'))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    method_index += 1\n",
    "    # display(HTML(f'<h3> {model_index}.{method_index} {method} </h3>'))\n",
    "    X, y = make_sampling(method, X_original, y_original)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 42)\n",
    "    score = cross_val_score(model, X, y, cv = 10, scoring='accuracy')\n",
    "\n",
    "    print('Charn values Original')\n",
    "    print(y.value_counts())\n",
    "    print('Total data: {}'.format(y.count()))\n",
    "\n",
    "    print('\\nCharn values Train')\n",
    "    print(y_train.value_counts())\n",
    "    print('Total data: {}'.format(y_train.count()))\n",
    "\n",
    "    print('\\nCharn values Test')\n",
    "    print(y_test.value_counts())\n",
    "    print('Total data: {}'.format(y_test.count()))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"*_\" * 20)\n",
    "    print(f\"Mean scores : {score.mean()}\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print(metrics.classification_report(y_pred_test, y_test))\n",
    "\n",
    "    # Learning curve start\n",
    "    print('Creating Learning curve for {} - {}'.format(name, method))\n",
    "    %time create_learningcurve(model, X, y)\n",
    "\n",
    "    pred_df = X_test.copy()\n",
    "    pred_df['churn'] = y_pred_test\n",
    "\n",
    "    print('\\n Gender Count in predited value with X_test set')\n",
    "    print('# ' * 10)\n",
    "    print(pred_df.gender.value_counts())\n",
    "    p_df = pred_df[['churn', 'gender']]\n",
    "    print('\\n')\n",
    "    p_df.insert(2, 'counter', 1)\n",
    "    print(p_df.groupby(['churn','gender',]).sum())\n",
    "    print('# ' * 10)\n",
    "\n",
    "    print(metrics.confusion_matrix(y_test, y_pred_test))\n",
    "    metrics.plot_confusion_matrix(model, X_test, y_test)\n",
    "    plt.show()\n",
    "\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    roc_auc_score = metrics.roc_auc_score(y_test, y_proba)\n",
    "    print('\\n\\n')\n",
    "    print(f'ROC AUC Score {roc_auc_score}')\n",
    "\n",
    "\n",
    "    # Additional matrix\n",
    "    df_pred = X_test\n",
    "    df_pred.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    pred = pd.Series(y_pred_test)\n",
    "    df_pred = df_pred.assign(churn=pred)\n",
    "\n",
    "    # df_pred = df_pred.assign(churn=y_test)\n",
    "\n",
    "    aif_df = TMDataset(data_frame=df_pred)\n",
    "    aif_df_labeled = aif_df.copy()\n",
    "    aif_df_labeled.labels = y_pred_test\n",
    "\n",
    "    result_tbl_cols = [\n",
    "        'Attribute',\n",
    "        'Mean difference', \n",
    "        'Positive Outcome',\n",
    "        'Negative', \n",
    "        'Differences', \n",
    "        'Disparate impact', \n",
    "        'Consistency',\n",
    "        'Statistical parity dif',\n",
    "    ]\n",
    "\n",
    "    result_rows = []\n",
    "    for p_attribute in aif_df.protected_attribute_names:\n",
    "        result_row = []\n",
    "        privileged_groups = [{p_attribute: 1}]\n",
    "        print(' * ' * 10)\n",
    "        print(privileged_groups)\n",
    "        unprivileged_groups = [{p_attribute: 0}]\n",
    "\n",
    "        metric_orig_train = BinaryLabelDatasetMetric(\n",
    "            aif_df,  unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "        clsf_metric = ClassificationMetric(\n",
    "            aif_df, aif_df_labeled, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "        print('\\n AIF 360 ')\n",
    "        print('\\n Statistical parity difference', clsf_metric.statistical_parity_difference())\n",
    "\n",
    "        print('\\n True possitve rate {} \\t True negative rate {} '.format(\n",
    "            clsf_metric.true_positive_rate(), clsf_metric.true_negative_rate()))\n",
    "\n",
    "        print('\\n Desparate impact ', clsf_metric.disparate_impact())\n",
    "        print('\\n Equal opportunity difference ', clsf_metric.equal_opportunity_difference())\n",
    "        print('\\n Average odds difference ', clsf_metric.average_odds_difference())\n",
    "        print('\\n Theil Index ', clsf_metric.theil_index())\n",
    "        print('\\n Binary Confusion Matric ')\n",
    "        print(clsf_metric.binary_confusion_matrix())\n",
    "        print('\\n ..........................')\n",
    "\n",
    "        text_expl = MetricTextExplainer(metric_orig_train)\n",
    "\n",
    "        result_row.append(p_attribute)\n",
    "        result_row.append(metric_orig_train.mean_difference())\n",
    "        result_row.append(metric_orig_train.num_positives())\n",
    "        result_row.append(metric_orig_train.num_negatives())\n",
    "\n",
    "        # this is to shutup the warning msg from sklearn\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', FutureWarning)\n",
    "            result_row.append(metric_orig_train.consistency())\n",
    "\n",
    "        result_row.append(metric_orig_train.disparate_impact())\n",
    "        result_row.append(metric_orig_train.consistency())\n",
    "        result_row.append(metric_orig_train.statistical_parity_difference())\n",
    "\n",
    "        result_rows.append(result_row)\n",
    "\n",
    "    result_df = pd.DataFrame(result_rows, columns=result_tbl_cols)\n",
    "    display(result_df)\n",
    "    # End Aif matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>1.1 Random Forest - original </h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charn values Original\n",
      "0    70000\n",
      "1    30000\n",
      "Name: churn, dtype: int64\n",
      "Total data: 100000\n",
      "\n",
      "Charn values Train\n",
      "0    46896\n",
      "1    20104\n",
      "Name: churn, dtype: int64\n",
      "Total data: 67000\n",
      "\n",
      "Charn values Test\n",
      "0    23104\n",
      "1     9896\n",
      "Name: churn, dtype: int64\n",
      "Total data: 33000\n",
      "\n",
      "\n",
      "*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_\n",
      "Mean scores : 0.8063100000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87     26750\n",
      "           1       0.49      0.78      0.60      6250\n",
      "\n",
      "    accuracy                           0.80     33000\n",
      "   macro avg       0.71      0.79      0.74     33000\n",
      "weighted avg       0.85      0.80      0.82     33000\n",
      "\n",
      "Creating Learning curve for Random Forest - original\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random Forest Original\n",
    "runModels(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random Forest [Adasyn]\n",
    "runModels(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random Forest [Smote]\n",
    "runModels(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random Forest [Rus]\n",
    "runModels(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random Forest [Ros]\n",
    "runModels(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(6, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(6, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "runModels(6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
